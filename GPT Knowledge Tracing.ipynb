{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT Knowledge Tracing.ipynb\n",
    "\n",
    "This file contains the code for the inference using the GPT-3.5 API in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and helper codes\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from time import sleep\n",
    "\n",
    "import pandas\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "import tiktoken\n",
    "\n",
    "from gpt_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data and topics (= KC) for our inference\n",
    "\n",
    "generate_new_file('dataverse_files/2_DBE_KT22_datafiles_100102_csv/KCs.csv',\n",
    "                  'dataverse_files/2_DBE_KT22_datafiles_100102_csv/Question_KC_Relationships.csv',\n",
    "                  'dataverse_files/2_DBE_KT22_datafiles_100102_csv/Generated_KC_Questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue preparing the data\n",
    "\n",
    "data = read_data('', # change with the test data file you want to use for inference\n",
    "                    'dataverse_files/2_DBE_KT22_datafiles_100102_csv/Questions.csv',\n",
    "                    'dataverse_files/2_DBE_KT22_datafiles_100102_csv/Generated_KC_Questions.csv',\n",
    "                    N = -1)\n",
    "data = remove_padding(data) # kept for compatibility with the original code, which added padding in case of unequal-length subsequences. (The current code keeps all subsequences of the same length.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API information for the OpenAI API. Replace with your own information (kept empty for security reasons)\n",
    "\n",
    "api_info = {\n",
    "    'api_key': \"\",\n",
    "    'api_version': \"\",\n",
    "    'azure_endpoint': \"\",\n",
    "    'model': \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions_of_model(preds, gts):\n",
    "    \"\"\"\n",
    "    Evaluate the predictions of a model, given the ground truth labels.\n",
    "\n",
    "    Args:\n",
    "        preds: List of predictions.\n",
    "        gts: List of ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        metrics: Dictionary of metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # The labels \"CORRECT\" and \"WRONG\", as returned by the GPT-3.5 model, are converted to 1 and 0, respectively\n",
    "    preds = [1 if pred == \"CORRECT\" else 0 for pred in preds]\n",
    "    gts = [1 if gt == \"CORRECT\" else 0 for gt in gts]\n",
    "\n",
    "    # Compute the metrics\n",
    "    report = classification_report(gts, preds, output_dict=True)\n",
    "\n",
    "    # Extract the metrics from the classification report\n",
    "    f1_0 = report['0']['f1-score']\n",
    "    f1_1 = report['1']['f1-score']\n",
    "\n",
    "    supp_0 = report['0']['support']\n",
    "    supp_1 = report['1']['support']\n",
    "\n",
    "    acc = report['accuracy']\n",
    "    balanced_acc = balanced_accuracy_score(gts, preds)\n",
    "\n",
    "    metrics = {\n",
    "        'f1_0': f1_0,\n",
    "        'f1_1': f1_1,\n",
    "        'supp_0': supp_0,\n",
    "        'supp_1': supp_1,\n",
    "        'acc': acc,\n",
    "        'bal_acc': balanced_acc\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: WRONG\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: WRONG\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "OpenAI result: WRONG\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: WRONG\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: WRONG\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: CORRECT\n",
      "OpenAI result: CORRECT\n",
      "Ground truth: WRONG\n",
      "Number of correct: 75\n",
      "Number of total 100\n",
      "Percentage: 75.0\n"
     ]
    }
   ],
   "source": [
    "# Generate the prompts to be used for GPT-3.5 inference\n",
    "prompts, gts = generate_prompts(data, incl_id = False, incl_q = False, incl_kc = False, incl_diff = True)\n",
    "prompts_sample, gts_sample = randomly_sample_prompts(prompts, gts, N = 100, seed = 0, max_token_len = 4096) # in the original code, we randomly \"sampled\" prompts, but for final run, this function effectively only shuffles the prompts and keeps those that fit within the maximum context length of our model\n",
    "\n",
    "# Generate predictions from the GPT-3.5 model\n",
    "preds = predict(prompts_sample, gts_sample, api_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_0': 0.3243243243243243, 'f1_1': 0.8466257668711655, 'supp_0': 19.0, 'supp_1': 81.0, 'acc': 0.75, 'bal_acc': 0.5838206627680311}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of the GPT-3.5 model\n",
    "metrics = evaluate_predictions_of_model(preds, gts_sample)\n",
    "\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
